{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a988074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ca8273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0801309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scale(xTrain, xTest):\n",
    "    \"\"\"\n",
    "    Preprocess the training data to have zero mean and unit variance.\n",
    "    The same transformation should be used on the test data. For example,\n",
    "    if the mean and std deviation of feature 1 is 2 and 1.5, then each\n",
    "    value of feature 1 in the test set is standardized using (x-2)/1.5.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xTrain : nd-array with shape n x d\n",
    "        Training data \n",
    "    xTest : nd-array with shape m x d\n",
    "        Test data \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xTrain : nd-array with shape n x d\n",
    "        Transformed training data with mean 0 and unit variance \n",
    "    xTest : nd-array with shape m x d\n",
    "        Transformed test data using same process as training.\n",
    "    \"\"\"\n",
    "    # Calculate mean and standard deviation of each feature\n",
    "    mean = np.mean(xTrain, axis=0)\n",
    "    std = np.std(xTrain, axis=0)\n",
    "\n",
    "    # Standardize training data\n",
    "    xTrain = (xTrain - mean) / std\n",
    "\n",
    "    # Standardize test data using same mean and standard deviation\n",
    "    xTest = (xTest - mean) / std\n",
    "\n",
    "    return xTrain, xTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab240891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_range(xTrain, xTest):\n",
    "    \"\"\"\n",
    "    Preprocess the data to have minimum value of 0 and maximum\n",
    "    value of 1.T he same transformation should be used on the test data.\n",
    "    For example, if the minimum and maximum of feature 1 is 0.5 and 2, then\n",
    "    then feature 1 of test data is calculated as:\n",
    "    (1 / (2 - 0.5)) * x - 0.5 * (1 / (2 - 0.5))\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xTrain : nd-array with shape n x d\n",
    "        Training data \n",
    "    xTest : nd-array with shape m x d\n",
    "        Test data \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xTrain : nd-array with shape n x d\n",
    "        Transformed training data with min 0 and max 1.\n",
    "    xTest : nd-array with shape m x d\n",
    "        Transformed test data using same process as training.\n",
    "    \"\"\"\n",
    "    # Calculate minimum and maximum of each feature\n",
    "    min = np.min(xTrain, axis=0)\n",
    "    max = np.max(xTrain, axis=0)\n",
    "\n",
    "    # Minmax scale training data\n",
    "    xTrain = (xTrain - min) / (max - min)\n",
    "\n",
    "    # Minmax scale test data using same minimum and maximum\n",
    "    xTest = (xTest - min) / (max - min)\n",
    "\n",
    "    return xTrain, xTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7be45933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_irr_feature(xTrain, xTest):\n",
    "    \"\"\"\n",
    "    Add 2 features using Gaussian distribution with 0 mean,\n",
    "    standard deviation of 1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xTrain : nd-array with shape n x d\n",
    "        Training data \n",
    "    xTest : nd-array with shape m x d\n",
    "        Test data \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xTrain : nd-array with shape n x (d+2)\n",
    "        Training data with 2 new noisy Gaussian features\n",
    "    xTest : nd-array with shape m x (d+2)\n",
    "        Test data with 2 new noisy Gaussian features\n",
    "    \"\"\"\n",
    "    irr_train = np.random.normal(0, 1, (xTrain.shape[0], 2))\n",
    "    irr_test = np.random.normal(0, 1, (xTest.shape[0], 2))\n",
    "    xTrain = np.concatenate((xTrain, irr_train), axis=1)\n",
    "    xTest = np.concatenate((xTest, irr_test), axis=1)\n",
    "    return xTrain, xTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dae97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_knn(xTrain, yTrain, xTest, yTest, preprocessing_func):\n",
    "    # Preprocess the data using the given function\n",
    "    xTrain, xTest = preprocessing_func(xTrain, xTest)\n",
    "\n",
    "    # Define a list of K values to try\n",
    "    k_list = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]\n",
    "\n",
    "    # Initialize a list to store the accuracies\n",
    "    accuracies = []\n",
    "\n",
    "    # Loop over the K values and train/test the KNN model\n",
    "    for k in k_list:\n",
    "        knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn_model.fit(xTrain, yTrain)\n",
    "        acc = knn_model.score(xTest, yTest)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    return k_list, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18cbee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_train_test(k, xTrain, yTrain, xTest, yTest):\n",
    "    \"\"\"\n",
    "    Given a specified k, train the knn model and predict\n",
    "    the labels of the test data. Returns the accuracy of\n",
    "    the resulting model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    k : int\n",
    "        The number of neighbors\n",
    "    xTrain : nd-array with shape n x d\n",
    "        Training data \n",
    "    yTrain : 1d array with shape n\n",
    "        Array of labels associated with training data.\n",
    "    xTest : nd-array with shape m x d\n",
    "        Test data \n",
    "    yTest : 1d array with shape m\n",
    "        Array of labels associated with test data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    acc : float\n",
    "        The accuracy of the trained knn model on the test data\n",
    "    \"\"\"\n",
    "    model = knn.Knn(k)\n",
    "    model.train(xTrain, yTrain['label'])\n",
    "    # predict the test dataset\n",
    "    yHatTest = model.predict(xTest)\n",
    "    return knn.accuracy(yHatTest, yTest['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbd77182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # set up the program to take in arguments from the command line\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"k\",\n",
    "                        type=int,\n",
    "                        help=\"the number of neighbors\")\n",
    "    parser.add_argument(\"--xTrain\",\n",
    "                        default=\"q4xTrain.csv\",\n",
    "                        help=\"filename for features of the training data\")\n",
    "    parser.add_argument(\"--yTrain\",\n",
    "                        default=\"q4yTrain.csv\",\n",
    "                        help=\"filename for labels associated with training data\")\n",
    "    parser.add_argument(\"--xTest\",\n",
    "                        default=\"q4xTest.csv\",\n",
    "                        help=\"filename for features of the test data\")\n",
    "    parser.add_argument(\"--yTest\",\n",
    "                        default=\"q4yTest.csv\",\n",
    "                        help=\"filename for labels associated with the test data\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    # load the train and test data\n",
    "    xTrain = pd.read_csv(args.xTrain)\n",
    "    yTrain = pd.read_csv(args.yTrain)\n",
    "    xTest = pd.read_csv(args.xTest)\n",
    "    yTest = pd.read_csv(args.yTest)\n",
    "\n",
    "    # no preprocessing\n",
    "    acc1 = knn_train_test(args.k, xTrain, yTrain, xTest, yTest)\n",
    "    print(\"Test Acc (no-preprocessing):\", acc1)\n",
    "    # preprocess the data using standardization scaling\n",
    "    xTrainStd, xTestStd = standard_scale(xTrain, xTest)\n",
    "    acc2 = knn_train_test(args.k, xTrainStd, yTrain, xTestStd, yTest)\n",
    "    print(\"Test Acc (standard scale):\", acc2)\n",
    "    # preprocess the data using min max scaling\n",
    "    xTrainMM, xTestMM = minmax_range(xTrain, xTest)\n",
    "    acc3 = knn_train_test(args.k, xTrainMM, yTrain, xTestMM, yTest)\n",
    "    print(\"Test Acc (min max scale):\", acc3)\n",
    "    # add irrelevant features\n",
    "    xTrainIrr, yTrainIrr = add_irr_feature(xTrain, xTest)\n",
    "    acc4 = knn_train_test(args.k, xTrainIrr, yTrain, yTrainIrr, yTest)\n",
    "    print(\"Test Acc (with irrelevant feature):\", acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65434364",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
